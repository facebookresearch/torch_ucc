name: CI

on: [push, pull_request]

env:
  OPENUCX_LINK: https://github.com/openucx/ucx.git
  UCC_LINK: https://github.com/openucx/ucc.git
  PARAM_LINK: https://github.com/facebookresearch/param

jobs:
  tests:
    runs-on: ubuntu-latest
    container:
      image: pytorch/pytorch:latest
    steps:
    - name: Install packages
      run: |
        apt-get update
        apt-get install -y --no-install-recommends build-essential git cmake libtool-bin wget autoconf automake
        conda uninstall -y pytorch torchvision
        pip3 install --pre torch -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html
    - name: Get UCX
      run: |
        git clone ${OPENUCX_LINK} /tmp/ucx
        cd /tmp/ucx
        ./autogen.sh
        ./contrib/configure-release-mt --without-java --disable-numa --prefix=/opt/ucx
        make -j install
    - name: Get UCC
      run: |
        git clone ${UCC_LINK} /tmp/ucc
        cd /tmp/ucc
        ./autogen.sh
        ./configure --with-ucx=/opt/ucx --prefix=/opt/ucc
        make -j install
    - uses: actions/checkout@v1
    - name: Build with UCX and UCC
      run: |
        UCX_HOME=/opt/ucx/ UCC_HOME=/opt/ucc/ WITH_CUDA=no python setup.py install
    - name: Tests
      run: |
        export LD_LIBRARY_PATH=/opt/ucx/lib:/opt/ucc/lib:$LD_LIBRARY_PATH
        /opt/ucx/bin/ucx_info -e -u t
        export UCX_LOG_LEVEL=info
        echo "UCC barrier"
        /bin/bash ./test/start_test.sh ./test/torch_barrier_test.py --backend=gloo
        echo "UCC alltoall"
        /bin/bash ./test/start_test.sh ./test/torch_alltoall_test.py --backend=gloo
        echo "UCC alltoallv"
        /bin/bash ./test/start_test.sh ./test/torch_alltoallv_test.py --backend=gloo
        echo "UCC allgather"
        /bin/bash ./test/start_test.sh ./test/torch_allgather_test.py --backend=gloo
        echo "UCC allreduce"
        /bin/bash ./test/start_test.sh ./test/torch_allreduce_test.py --backend=gloo
        echo "UCC broadcast"
        /bin/bash ./test/start_test.sh ./test/torch_bcast_test.py --backend=gloo
        echo "UCC pt2pt"
        /bin/bash ./test/start_test.sh ./test/torch_pt2pt_test.py --backend=gloo
    - name: Test PARAM
      run: |
        git clone ${PARAM_LINK} /tmp/param
        export LD_LIBRARY_PATH=/opt/ucx/lib:/opt/ucc/lib:$LD_LIBRARY_PATH
        echo "PARAM-Comms Allreduce w/ UCC"
        /bin/bash ./test/start_test.sh /tmp/param/train/comms/pt/comms.py --backend ucc --device cpu --b 4 --e 4M --c 1 --collective all_reduce
        echo "PARAM-Comms Alltoall w/ UCC"
        /bin/bash ./test/start_test.sh /tmp/param/train/comms/pt/comms.py --backend ucc --device cpu --b 4 --e 4M --c 1 --collective all_to_all
        echo "PARAM-Comms Alltoallv w/ UCC"
        /bin/bash ./test/start_test.sh /tmp/param/train/comms/pt/comms.py --backend ucc --device cpu --b 4 --e 4M --c 1 --collective all_to_allv
        echo "PARAM-Comms Broadcast w/ UCC"
        /bin/bash ./test/start_test.sh /tmp/param/train/comms/pt/comms.py --backend ucc --device cpu --b 4 --e 4M --c 1 --collective broadcast
        echo "PARAM-Comms Allgather w/ UCC"
        /bin/bash ./test/start_test.sh /tmp/param/train/comms/pt/comms.py --backend ucc --device cpu --b 4 --e 4M --c 1 --collective all_gather
        echo "PARAM-Comms Quantized Allreduce w/ UCC (use of c10d future)"
        /bin/bash ./test/start_test.sh /tmp/param/train/comms/pt/comms.py --backend ucc --device cpu --b 4 --e 4M --c 1 --bitwidth 16 --collective all_reduce
        echo "PARAM-Comms Non-blocking Allreduce w/ UCC"
        /bin/bash ./test/start_test.sh /tmp/param/train/comms/pt/comms.py --backend ucc --device cpu --b 4 --e 4M --c 1 --z 0 --collective all_reduce
        echo "PARAM-Comms Non-blocking Alltoall w/ UCC"
        /bin/bash ./test/start_test.sh /tmp/param/train/comms/pt/comms.py --backend ucc --device cpu --b 4 --e 4M --c 1 --z 0 --collective all_to_all
        echo "PARAM-Comms Non-blocking Alltoallv w/ UCC"
        /bin/bash ./test/start_test.sh /tmp/param/train/comms/pt/comms.py --backend ucc --device cpu --b 4 --e 4M --c 1 --z 0 --collective all_to_allv
        echo "PARAM-Comms Pt2pt w/ UCC"
        /bin/bash ./test/start_test.sh /tmp/param/train/comms/pt/comms.py --backend ucc --device cpu --b 4 --e 4M --c 1 --pt2pt one2one --src-ranks 0 --dst-ranks 1
